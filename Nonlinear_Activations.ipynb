{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPvVgz8+PyTK6M2Z6zWcUIw"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Decoding Neural Responses**\n"
      ],
      "metadata": {
        "id": "M41jpJNDppyZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgLk6kbTlyKA",
        "outputId": "939d52c5-ddf4-48d6-d3e9-e76746533aa4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "decoded orientation: -0.24 degrees\n",
            "true orientation: 42.48 degrees\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "class DeepNetReLU(nn.Module):\n",
        "    \"\"\"Network with a single hidden layer h with a ReLU\"\"\"\n",
        "\n",
        "    def __init__(self, n_inputs, n_hidden):\n",
        "        super().__init__()  # needed to invoke the properties of the parent class nn.Module\n",
        "        self.in_layer = nn.Linear(n_inputs, n_hidden)  # neural activity --> hidden units\n",
        "        self.out_layer = nn.Linear(n_hidden, 1)  # hidden units --> output\n",
        "\n",
        "    def forward(self, r):\n",
        "        # Apply the linear transformation and ReLU activation\n",
        "        h = torch.relu(self.in_layer(r))  # h is size (n_inputs, n_hidden)\n",
        "        y = self.out_layer(h)  # y is size (n_inputs, 1)\n",
        "        return y\n",
        "\n",
        "# Helper function to simulate the data fetching\n",
        "def get_data(index, resp_train, stimuli_train):\n",
        "    return torch.tensor(resp_train[index], dtype=torch.float32), torch.tensor(stimuli_train[index], dtype=torch.float32)\n",
        "\n",
        "# Assuming n_neurons, resp_train, and stimuli_train are defined somewhere\n",
        "n_neurons = 100\n",
        "resp_train = np.random.rand(10, n_neurons)  # 10 samples with n_neurons features each\n",
        "stimuli_train = np.random.rand(10) * 180  # 10 random stimulus orientations between 0 and 180 degrees\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(1)\n",
        "torch.manual_seed(1)\n",
        "\n",
        "# Initialize a deep network with M=200 hidden units\n",
        "net = DeepNetReLU(n_neurons, 200)\n",
        "\n",
        "# Get neural responses (r) and orientation (ori) to one stimulus in dataset\n",
        "r, ori = get_data(0, resp_train, stimuli_train)  # using helper function get_data\n",
        "\n",
        "# Decode orientation from these neural responses using initialized network\n",
        "out = net(r)  # compute output from network, equivalent to net.forward(r)\n",
        "\n",
        "print(f'decoded orientation: {out.item():.2f} degrees')\n",
        "print(f'true orientation: {ori.item():.2f} degrees')\n"
      ]
    }
  ]
}